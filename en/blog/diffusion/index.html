<!doctype html><html itemscope lang=en-us itemtype=http://schema.org/WebPage><head><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1,maximum-scale=5"><meta name=theme-name content="hugoplate"><link rel="shortcut icon" href=/images/favicon_hueb84ecec72665a83aae8c940dfe71474_1906_96x0_resize_lanczos_3.png type=image/x-icon><link rel=icon href=/images/favicon_hueb84ecec72665a83aae8c940dfe71474_1906_96x0_resize_lanczos_3.png type=image/x-icon><link rel=icon type=image/png sizes=48x48 href=/images/favicon_hueb84ecec72665a83aae8c940dfe71474_1906_48x0_resize_lanczos_3.png><link rel=icon type=image/png sizes=96x96 href=/images/favicon_hueb84ecec72665a83aae8c940dfe71474_1906_96x0_resize_lanczos_3.png><link rel=apple-touch-icon sizes=144x144 href=/images/favicon_hueb84ecec72665a83aae8c940dfe71474_1906_144x0_resize_lanczos_3.png><link rel=manifest href=/manifest.webmanifest><meta name=msapplication-TileColor content="#ddd"><meta name=theme-color content="#ffffff"><base href=https://lhfgghc.github.io/en/blog/diffusion/><title>【学习笔记】扩散模型的基本原理与训练方法</title>
<meta name=keywords content="Boilerplate,Hugo"><meta name=description content="this is meta description"><meta name=author content="zeon.studio"><meta property="og:image" content="https://lhfgghc.github.io/images/diffusion/process.png"><meta name=twitter:image content="https://lhfgghc.github.io/images/diffusion/process.png"><meta name=twitter:card content="summary_large_image"><meta property="og:image:width" content="1235"><meta property="og:image:height" content="226"><meta property="og:image:type" content="image/
        .png
      "><meta property="og:title" content="【学习笔记】扩散模型的基本原理与训练方法"><meta property="og:description" content="this is meta description"><meta property="og:type" content="website"><meta property="og:url" content="https://lhfgghc.github.io/en/blog/diffusion/"><meta name=twitter:title content="【学习笔记】扩散模型的基本原理与训练方法"><meta name=twitter:description content="this is meta description"><script>let indexURL="https://lhfgghc.github.io/en/searchindex.json",includeSectionsInSearch=["blog"],search_no_results="未找到结果",search_initial_message="输入内容以搜索"</script><meta http-equiv=x-dns-prefetch-control content="on"><link rel=preconnect href=https://use.fontawesome.com crossorigin><link rel=preconnect href=//cdnjs.cloudflare.com><link rel=preconnect href=//www.googletagmanager.com><link rel=preconnect href=//www.google-analytics.com><link rel=dns-prefetch href=https://use.fontawesome.com><link rel=dns-prefetch href=//ajax.googleapis.com><link rel=dns-prefetch href=//cdnjs.cloudflare.com><link rel=dns-prefetch href=//www.googletagmanager.com><link rel=dns-prefetch href=//www.google-analytics.com><link rel=dns-prefetch href=//fonts.googleapis.com><link rel=dns-prefetch href=//connect.facebook.net><link rel=dns-prefetch href=//platform.linkedin.com><link rel=dns-prefetch href=//platform.twitter.com><link rel=preconnect href=https://fonts.googleapis.com><link rel=preconnect href=https://fonts.gstatic.com crossorigin><script>(function(){const e=document.createElement("link");e.href="https://fonts.googleapis.com/css2?family=Heebo:wght@400;600&family=Signika:wght@500;700&display=swap",e.type="text/css",e.rel="stylesheet",document.head.appendChild(e)})()</script><link href="/css/style.min.4c1d4c3120637c4b33d33d38988a2525a8e15057b5ab0cfa95ce5147d4c95adc.css" integrity="sha256-TB1MMSBjfEsz0z04mIolJajhUFe1qwz6lc5RR9TJWtw=" rel=stylesheet><link defer async rel=stylesheet href="/css/style-lazy.min.ec14d2549e8e0fbaf9af20dcc88fad37fb352e5bd5978a801dc1c3f5a5922174.css" integrity="sha256-7BTSVJ6OD7r5ryDcyI+tN/s1LlvVl4qAHcHD9aWSIXQ=" media=print onload='this.media="all",this.onload=null'></head><body><header class="header sticky top-0 z-30"><nav class="navbar container"><div class=order-0><a class="navbar-brand block" href=/en/><img fetchpriority=high decoding=async class="img logo-light" width=160 height=32 src=/images/logo-1_hubf409f6fc77577ff09f7cacc73653041_8513_320x0_resize_q80_h2_lanczos_3.webp alt=Hugoplate onerror='this.onerror=null,this.src="/images/logo-1_hubf409f6fc77577ff09f7cacc73653041_8513_320x0_resize_lanczos_3.png"'>
<img fetchpriority=high decoding=async class="img logo-dark" width=160 height=32 src=/images/logo-2_hu06a606f114baa5722e40403b02652855_7961_320x0_resize_q80_h2_lanczos_3.webp alt=Hugoplate onerror='this.onerror=null,this.src="/images/logo-2_hu06a606f114baa5722e40403b02652855_7961_320x0_resize_lanczos_3.png"'></a></div><input id=nav-toggle type=checkbox class=hidden>
<label for=nav-toggle class="order-3 cursor-pointer flex items-center lg:hidden text-dark dark:text-white lg:order-1"><svg id="show-button" class="h-6 fill-current block" viewBox="0 0 20 20"><title>Menu Open</title><path d="M0 3h20v2H0V3zm0 6h20v2H0V9zm0 6h20v2H0V0z"/></svg><svg id="hide-button" class="h-6 fill-current hidden" viewBox="0 0 20 20"><title>Menu Close</title><polygon points="11 9 22 9 22 11 11 11 11 22 9 22 9 11 -2 11 -2 9 9 9 9 -2 11 -2" transform="rotate(45 10 10)"/></svg></label><ul id=nav-menu class="navbar-nav order-3 hidden lg:flex w-full pb-6 lg:order-1 lg:w-auto lg:space-x-2 lg:pb-0 xl:space-x-8"><li class=nav-item><a class=nav-link href=/en/>主页</a></li><li class=nav-item><a class=nav-link href=/en/blog/>学习笔记</a></li><li class=nav-item><a class=nav-link href=/en/about/>个人信息</a></li><li class="nav-item nav-dropdown group relative"><span class="nav-link
inline-flex items-center">其它<svg class="h-4 w-4 fill-current" viewBox="0 0 20 20"><path d="M9.293 12.95l.707.707L15.657 8l-1.414-1.414L10 10.828 5.757 6.586 4.343 8z"/></svg></span><ul class="nav-dropdown-list lg:group-hover:visible lg:group-hover:opacity-100"><li class=nav-dropdown-item><a class=nav-dropdown-link href=/en/elements/>样式Draft</a></li><li class=nav-dropdown-item><a class=nav-dropdown-link href=/en/privacy-policy/>相关说明</a></li><li class=nav-dropdown-item><a class=nav-dropdown-link href=/en/categories/>笔记分类</a></li></ul></li></ul><div class="order-1 ml-auto flex items-center md:order-2 lg:ml-0"><button aria-label=search class="border-border text-dark hover:text-primary dark:border-darkmode-border mr-5 inline-block border-r pr-5 text-xl dark:text-white dark:hover:text-darkmode-primary" data-target=search-modal>
<i class="fa-solid fa-search"></i></button><div class="theme-switcher mr-5"><input id=theme-switcher data-theme-switcher type=checkbox>
<label for=theme-switcher><span class=sr-only>theme switcher</span>
<span><svg class="absolute left-1/2 top-1/2 -translate-x-1/2 -translate-y-1/2 z-10 opacity-100 dark:opacity-0" viewBox="0 0 56 56" fill="#fff" height="16" width="16"><path d="M30 4.6c0-1-.9-2-2-2a2 2 0 00-2 2v5c0 1 .9 2 2 2s2-1 2-2zm9.6 9a2 2 0 000 2.8c.8.8 2 .8 2.9.0L46 13a2 2 0 000-2.9 2 2 0 00-3 0zm-26 2.8c.7.8 2 .8 2.8.0.8-.7.8-2 0-2.9L13 10c-.7-.7-2-.8-2.9.0-.7.8-.7 2.1.0 3zM28 16A12 12 0 0016 28a12 12 0 0012 12 12 12 0 0012-12A12 12 0 0028 16zm23.3 14c1.1.0 2-.9 2-2s-.9-2-2-2h-4.9a2 2 0 00-2 2c0 1.1 1 2 2 2zM4.7 26a2 2 0 00-2 2c0 1.1.9 2 2 2h4.9c1 0 2-.9 2-2s-1-2-2-2zm37.8 13.6a2 2 0 00-3 0 2 2 0 000 2.9l3.6 3.5a2 2 0 002.9.0c.8-.8.8-2.1.0-3zM10 43.1a2 2 0 000 2.9c.8.7 2.1.8 3 0l3.4-3.5c.8-.8.8-2.1.0-2.9s-2-.8-2.9.0zm20 3.4c0-1.1-.9-2-2-2a2 2 0 00-2 2v4.9c0 1 .9 2 2 2s2-1 2-2z"/></svg><svg class="absolute left-1/2 top-1/2 -translate-x-1/2 -translate-y-1/2 z-10 opacity-0 dark:opacity-100" viewBox="0 0 24 24" fill="none" height="16" width="16"><path fill="#000" fill-rule="evenodd" clip-rule="evenodd" d="M8.2 2.2c1-.4 2 .6 1.6 1.5-1 3-.4 6.4 1.8 8.7a8.4 8.4.0 008.7 1.8c1-.3 2 .5 1.5 1.5v.1A10.3 10.3.0 0112.4 22 10.3 10.3.0 013.2 6.7c1-2 2.9-3.5 4.9-4.4z"/></svg></span></label></div><script>var darkMode=!1,themeSwitch;window.matchMedia("(prefers-color-scheme: dark)").matches&&(darkMode=!0),localStorage.getItem("theme")==="dark"?darkMode=!0:localStorage.getItem("theme")==="light"&&(darkMode=!1),darkMode&&document.documentElement.classList.toggle("dark"),themeSwitch=document.querySelectorAll("[data-theme-switcher]"),document.addEventListener("DOMContentLoaded",()=>{[].forEach.call(themeSwitch,function(e){e.checked=!!darkMode,e.addEventListener("click",()=>{document.documentElement.classList.toggle("dark"),localStorage.setItem("theme",document.documentElement.classList.contains("dark")?"dark":"light")})})})</script></div></nav></header><div class=search-modal aria-hidden=true style=--color-primary:#121212><div data-target=close-search-modal class=search-modal-overlay></div><div class=search-wrapper data-image=true data-description=true data-tags=true data-categories=true><div class=search-wrapper-header><label for=search-modal-input style=margin-top:-1px><span class=sr-only>search icon</span>
<svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512" height="18" width="18" class="search-icon" data-type="search"><path fill="currentcolor" d="M416 208c0 45.9-14.9 88.3-40 122.7L502.6 457.4c12.5 12.5 12.5 32.8.0 45.3s-32.8 12.5-45.3.0L330.7 376c-34.4 25.2-76.8 40-122.7 40C93.1 416 0 322.9.0 208S93.1.0 208 0 416 93.1 416 208zM208 352a144 144 0 100-288 144 144 0 100 288z"/></svg>
<svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512" height="18" width="18" class="search-reset" data-type="reset"><path fill="currentcolor" d="M256 512A256 256 0 10256 0a256 256 0 100 512zM175 175c9.4-9.4 24.6-9.4 33.9.0l47 47 47-47c9.4-9.4 24.6-9.4 33.9.0s9.4 24.6.0 33.9l-47 47 47 47c9.4 9.4 9.4 24.6.0 33.9s-24.6 9.4-33.9.0l-47-47-47 47c-9.4 9.4-24.6 9.4-33.9.0s-9.4-24.6.0-33.9l47-47-47-47c-9.4-9.4-9.4-24.6.0-33.9z"/></svg>
</label><input id=search-modal-input type=text data-search-input autocomplete=off aria-label=Search placeholder=搜索></div><div class=search-wrapper-body><div class=search-result data-search-result></div><span class=search-result-empty>输入内容以搜索</span></div><div class=search-wrapper-footer><span><kbd><svg xmlns="http://www.w3.org/2000/svg" width="14" height="14" fill="currentcolor" viewBox="0 0 16 16"><path d="M3.204 11h9.592L8 5.519 3.204 11zm-.753-.659 4.796-5.48a1 1 0 011.506.0l4.796 5.48c.566.647.106 1.659-.753 1.659H3.204a1 1 0 01-.753-1.659z"/></svg>
</kbd><kbd><svg xmlns="http://www.w3.org/2000/svg" width="14" height="14" fill="currentcolor" style="margin-top:1px" viewBox="0 0 16 16"><path d="M3.204 5h9.592L8 10.481 3.204 5zm-.753.659 4.796 5.48a1 1 0 001.506.0l4.796-5.48c.566-.647.106-1.659-.753-1.659H3.204a1 1 0 00-.753 1.659z"/></svg>
</kbd>导航
</span><span><kbd><svg xmlns="http://www.w3.org/2000/svg" width="12" height="12" fill="currentcolor" style="display:inline-block" viewBox="0 0 16 16"><path fill-rule="evenodd" d="M14.5 1.5a.5.5.0 01.5.5v4.8a2.5 2.5.0 01-2.5 2.5H2.707l3.347 3.346a.5.5.0 01-.708.708l-4.2-4.2a.5.5.0 010-.708l4-4a.5.5.0 11.708.708L2.707 8.3H12.5A1.5 1.5.0 0014 6.8V2a.5.5.0 01.5-.5z"/></svg>
</kbd>选择
</span><span class=search-result-info></span>
<span data-target=close-search-modal><kbd>ESC</kbd> 关闭</span></div></div></div><main><section class="section pt-7"><div class=container><div class="row justify-center"><article class=lg:col-10><div class=mb-10><picture><source srcset=/images/diffusion/process_hucaeaf4e39aab7718665e67c263b83e8d_100488_545x0_resize_q80_h2_lanczos_3.webp media="(max-width: 575px)"><source srcset=/images/diffusion/process_hucaeaf4e39aab7718665e67c263b83e8d_100488_600x0_resize_q80_h2_lanczos_3.webp media="(max-width: 767px)"><source srcset=/images/diffusion/process_hucaeaf4e39aab7718665e67c263b83e8d_100488_700x0_resize_q80_h2_lanczos_3.webp media="(max-width: 991px)"><source srcset=/images/diffusion/process_hucaeaf4e39aab7718665e67c263b83e8d_100488_1110x0_resize_q80_h2_lanczos_3.webp><img loading=lazy decoding=async src=/images/diffusion/process_hucaeaf4e39aab7718665e67c263b83e8d_100488_1110x0_resize_lanczos_3.png class="w-full rounded img" alt=【学习笔记】扩散模型的基本原理与训练方法 width=1235 height=226></picture></div><h1 class="h2 mb-4">【学习笔记】扩散模型的基本原理与训练方法</h1><ul class=mb-4><li class="mr-4 inline-block"><a href=/en/authors/liang-hangfeng/><i class="fa-regular fa-circle-user mr-2"></i>Liang Hangfeng</a></li><li class="mr-4 inline-block"><i class="fa-regular fa-folder mr-2"></i>
<a href=/en/categories/%e6%b7%b1%e5%ba%a6%e5%ad%a6%e4%b9%a0/>深度学习
,
</a><a href=/en/categories/%e5%ad%a6%e4%b9%a0%e7%ac%94%e8%ae%b0/>学习笔记</a></li><li class="mr-4 inline-block"><i class="fa-regular fa-clock mr-2"></i>
December 14, 2023</li></ul><div class="content mb-10"><h3 id=1-diffusion前向过程>1. Diffusion前向过程</h3><p>给定采样自数据集的真实图片$x_0 \sim q(x)$，并对其添加高斯噪声，共进行$T$步，称该过程为$q$过程，能够得到添加噪声后的图片分布$x_1,x_2,&mldr;,x_T$。</p><p>将加噪的过程看作一个马尔可夫过程，即$t$时刻的状态只与$t-1$时刻有关，设置超参数$\beta_t \in (0,1), t\in(1,T)$ ，本质上该超参数即为每一时刻下添加的高斯分布的方差。至此可以将该前向$q$过程写成以下形式，表示在$x_{t-1}$满足的分布前提下，$x_{t}$的方差为$\beta_t$，均值则受到了前一个状态的影响。
$$
q(x_t|x_{t-1})=\mathcal N(x_t;\sqrt{1-\beta_t}x_{t-1},\beta_t \mathbf{I})
$$
实际场景中，$\beta$是随着$t$的增大而递增的，那么当$t$很大时，$\beta_t$ 趋近于1，则$x_t$满足的分布接近于标准正态分布。【$\beta_t$这一超参数的存在本质是描述方差，但却在均值上乘上了$\sqrt{1-\beta_t}$，这能够使得均值在$t$很大的时候趋向于0，整个分布则为标准正态分布。】</p><p>由于以上过程看作一个马尔可夫过程，因此根据乘法公式可以写出以下表达式：
$$
q(x_{1:T}|x_0)=\prod_{t=1}^{T}q(x_t|x_{t-1})
$$</p><h4 id=重参数技巧reparameterization-trick>重参数技巧（reparameterization trick）</h4><p>以上前向的$q$过程的表达形式是采样形式的，表示在某个分布中进行随机采样，这回导致过程有随机性，无法反向传播梯度，为了使该采样过程变得可导，使用冲参数技巧，引入一个固定的随机变量$\epsilon$实现。</p><p>例如需要进行以下采样：$z \sim \mathcal N (z;\mu_\theta,\sigma_{\theta}^{2}\mathbf{I})$，可以写成：$z=\mu_{\theta}+\sigma_{\theta}\odot\epsilon$，这样的话$z$依旧是一个随机变量，但对于$\mu_{\theta}$和$\sigma_{\theta}$等含有网络参数的参数，能够通过$z$进行梯度的求取，随机性完全来自于固定不变服从标注正态分布的$\epsilon $中了。</p><p>那么对于原先的$q$过程，可以使用重参数技巧重写$x_t$，即：
$$
x_t=\sqrt{1-\beta_t}x_{t-1}+\sqrt{\beta_t}z，z \sim \mathcal N (0,\mathbf{I})
$$</p><h4 id=使用统一的方法表示x_t>使用统一的方法表示$x_t$</h4><p>由于上述扩散过程是一步步进行的，为了能够快速得到$x_t$，考虑使用$x_0$和$\beta$进行统一表示。</p><p>首先假设$\alpha_t=1-\beta_t$，并记$\overline{\alpha_t}=\prod_{i=1}^{T}\alpha_i$。</p><p>则对$x_t$有以下推导过程：</p><p>$$
\begin{aligned} %aligned命令对齐，在对齐的地方用"&"
x_t &=\sqrt{\alpha_t}x_{t-1}+\sqrt{1-\alpha_t}z_1 \\
&=\sqrt{\alpha_t}(\sqrt{\alpha_{t-1}}x_{t-2}+\sqrt{1-\alpha_{t-1}}z_2)+\sqrt{1-\alpha_t}z_1 \\
&=\sqrt{\alpha_t \alpha_{t-1}}x_{t-2}+\sqrt{\alpha_t(1-\alpha_{t-1})}z_2+\sqrt{1-\alpha_t}z_1 \\
&=\sqrt{\alpha_t \alpha_{t-1}}x_{t-2}+\sqrt{1-\alpha_t \alpha_{t-1}}\overline{z_2} \\
& &mldr; \\
&=\sqrt{\overline{\alpha_t}}x_0+\sqrt{1-\overline{\alpha_t}}\ \overline{z_t}
\end{aligned}
$$</p><p>其中对于$\sqrt{\alpha_t(1-\alpha_{t-1})}z_2+\sqrt{1-\alpha_t}z_1=\sqrt{1-\alpha_t \alpha_{t-1}}\overline{z_2}$的推导过程，有以下分析：</p><p>$$
\sqrt{\alpha_t(1-\alpha_{t-1})}z_2 \sim \mathcal N(0,\alpha_t(1-\alpha_{t-1})\mathbf{I}) \\
\sqrt{1-\alpha_t}z_1 \sim \mathcal N (0,(1-\alpha_t)\mathbf{I}) \\
\sqrt{\alpha_t(1-\alpha_{t-1})}z_2+\sqrt{1-\alpha_t}z_1 \sim \mathcal N(0,(1-\alpha_t \alpha_{t-1})\mathbf{I}) \\
$$</p><p>对于得到的混合高斯分布$\mathcal N(0,(1-\alpha_t \alpha_{t-1})\mathbf{I})$，可以表达为$\sqrt{1-\alpha_t \alpha_{t-1}}\overline{z_2}$，对于$\overline{z_2}$依然服从的是标准高斯分布。</p><p>综上，对于$x_t$的表达式形式为$x_t=\sqrt{\overline{\alpha_t}}x_0+\sqrt{1-\overline{\alpha_t}}z$，采样形式为$q(x_t|x_0) \sim \mathcal N(x_t;\sqrt{\overline{\alpha_t}}x_0,(1-\overline{\alpha_t})\mathbf{I})$。可以看成原始图片与高斯噪声的加权求和结果。</p><h3 id=2-diffusion逆向推断>2. Diffusion逆向推断</h3><p>该过程可以看成前向$q$过程的逆过程，即去噪过程。目前在这里我们已知所有的前向过程$q(x_t|x_{t-1})$，想要从标准正态分布中逐步去噪得到最终的原图分布，即从$x_T$得到$x_0$，那么就需要知道$q(x_{t-1}|x_t)$。但这是十分困难的，因此考虑使用深度神经网络来对该分布进行预测，即训练一个模型使其能够做到$p_{\theta}(x_{t-1}|x_t)$。【即让神经网络去学习去噪的过程】</p><p>对于$p_{\theta}(x_{t-1}|x_{t})$，写成正态分布的表达形式，即为下式，可以看到我们需要使网络根据$x_t$和$t$学习得到分布的均值与方差。</p><p>$$
p_{\theta}(x_{t-1}|x_t)=\mathcal N (x_{t-1};\mu_{\theta}(x_t,t),\Sigma_{\theta}(x_t,t))
$$</p><p>虽然$q(x_{t-1}|x_t)$难以直接得到，但是可以引入已知的原图像分布$x_0$的先验知识，尝试得到$q(x_{t-1}|x_t,x_0)$，可以进行以下过程推导：</p><p>$$
\begin{aligned}
q(x_{t-1}|x_t,x_0)&=\frac{q(x_{t-1},x_{t},x_{0})}{q(x_t,x_0)} \\
&=\frac{q(x_{t-1},x_t,x_0)}{q(x_{t-1},x_0)}\frac{q(x_{t-1},x_0)}{q(x_t,x_0)} \\
&=q(x_t|x_{t-1},x_0)\frac{\frac{q(x_{t-1},x_0)}{q_{x_0}}}{\frac{q(x_t,x_0)}{q_{x_0}}}\\
&=q(x_t|x_{t-1},x_0)\frac{q(x_{t-1}|x_0)}{q(x_t|x_0)}
\end{aligned}
$$</p><p>由此将加入先验知识的逆向分布转换为正向分布的表达式。</p><p>对于几个前向过程进行表达式说明：</p><p>$$
q(x_{t-1}|x_0)=\sqrt{\overline{\alpha_{t-1}}}x_0+\sqrt{1-\overline{\alpha_{t-1}}}z \sim \mathcal N (\sqrt{\overline{\alpha_{t-1}}}x_0,1-\overline{\alpha_{t-1}}) \\
q(x_{t}|x_0)=\sqrt{\overline{\alpha_{t}}}x_0+\sqrt{1-\overline{\alpha_{t}}}z \sim \mathcal N (\sqrt{\overline{\alpha_{t}}}x_0,1-\overline{\alpha_{t}})
$$</p><p>由于$q$过程是马尔可夫过程，则有：</p><p>$$
q(x_t|x_{t-1},x_0)=q(x_t|x_{t-1})=\sqrt{\alpha_{t}}x_{t-1}+\sqrt{1-\alpha_{t}}z \sim \mathcal N (\sqrt{\alpha_{t}}x_{t-1},1-\alpha_{t})
$$</p><p>而对于高斯分布，我们能够使用概率密度函数的形式进行表达，即：$\mathcal N(\mu,\sigma^2)\propto exp(-\frac{(x-\mu)^2}{2\sigma^2})$，则考虑使用概率密度函数描述$q(x_{t-1}|x_0)、q(x_t|x_0)、q(x_t|x_{t-1},x_0)$，如下表达式所示：</p><p>$$
q(x_{t-1}|x_0)\propto exp(-\frac{(x_{t-1}-\sqrt{\overline{\alpha_{t-1}}}x_0)^2}{2(1-\overline{\alpha_{t-1}})}) \\
q(x_{t}|x_0)\propto exp(-\frac{(x_{t}-\sqrt{\overline{\alpha_{t}}}x_0)^2}{2(1-\overline{\alpha_{t}})}) \\
q(x_t|x_{t-1},x_0)\propto exp(-\frac{(x_{t}-\sqrt{\alpha_{t}}x_{t-1})^2}{2(1-\alpha_{t})})
$$</p><p>则最终可以表达$q(x_{t-1}|x_t,x_0)$，如下推导所示。由于$q(x_{t-1}|x_t,x_0)$是关于$x_{t-1}$的表达式，则需要进行同类相合并</p><p>$$
\begin{aligned}
q(x_{t-1}|x_t,x_0)
&=q(x_t|x_{t-1},x_0)\frac{q(x_{t-1}|x_0)}{q(x_t|x_0)} \\
&\propto exp(-\frac{(x_{t-1}-\sqrt{\overline{\alpha_{t-1}}}x_0)^2}{2(1-\overline{\alpha_{t-1}})}) +
exp(-\frac{(x_{t}-\sqrt{\alpha_{t}}x_{t-1})^2}{2(1-\alpha_{t})}) -
exp(-\frac{(x_{t}-\sqrt{\overline{\alpha_{t}}}x_0)^2}{2(1-\overline{\alpha_{t}})}) \\
&=exp(-\frac{1}{2}(\frac{(x_{t-1}-\sqrt{\overline{\alpha_{t-1}}}x_0)^2}{1-\overline{\alpha_{t-1}}}+\frac{(x_{t}-\sqrt{\alpha_{t}}x_{t-1})^2}{1-\alpha_{t}}-\frac{(x_{t}-\sqrt{\overline{\alpha_{t}}}x_0)^2}{1-\overline{\alpha_{t}}})) \\
&=exp(-\frac{1}{2}((\frac{\alpha_t}{1-\alpha_t}+\frac{1}{1-\overline{\alpha_{t-1}}})x_{t-1}^2-(\frac{2\sqrt{\alpha_t}}{1-\alpha_t}x_t+\frac{2\sqrt{\overline{\alpha_{t-1}}}}{1-\overline{\alpha_{t-1}}}x_0)x_{t-1}+C(x_t,x_0)))
\end{aligned}
$$</p><p>其中$C(x_t,x_0)$不含$x_{t-1}$。</p><p>考虑到对于概率密度的表达式，可以进行展开操作，即$\mathcal N(\mu,\sigma^2)\propto exp(-\frac{(x-\mu)^2}{2\sigma^2})=exp(-\frac{1}{2}(\frac{1}{\sigma^2}x^2-\frac{2\mu}{\sigma^2}x+\frac{\mu^2}{\sigma^2}))$，与$q(x_{t-1}|x_t,x_0)$的表达式一一对应可知。</p><p>$$
\frac{1}{\sigma^2}=\frac{\alpha_t}{1-\alpha_t}+\frac{1}{1-\overline{\alpha_{t-1}}} \\
\sigma^2 =\frac{(1-\alpha_t)(1-\overline{\alpha_{t-1}})}{\alpha_t(1-\overline{\alpha_{t-1}})+(1-\alpha_t)}=\frac{\beta_t(1-\overline{\alpha_{t-1}})}{\alpha_t(1-\overline{\alpha_{t-1}})+\beta_t} \\
=\frac{1-\overline{\alpha_{t-1}}}{1-\overline{\alpha_t}}\beta_t
$$</p><p>对于均值，有求得表达式：</p><p>$$
\frac{2\mu}{\sigma^2}=\frac{2\sqrt{\alpha_t}}{1-\alpha_t}x_t+\frac{2\sqrt{\overline{\alpha_{t-1}}}}{-\overline{\alpha_{t-1}}}x_0 \\
\mu=\frac{\sqrt{\alpha_t}(1-\overline{\alpha_{t-1}})}{1-\overline{\alpha_{t}}}x_t+\frac{\sqrt{\overline{\alpha_{t-1}}}\beta_t}{1-\overline{\alpha_t}}x_0
$$</p><p>至此，我们在加入$x_0$的先验知识后，能够描述出分布$q(x_{t-1}|x_t,x_0)$的均值和方差的表达式，即</p><p>$$
\mu=\frac{\sqrt{\alpha_t}(1-\overline{\alpha_{t-1}})}{1-\overline{\alpha_{t}}}x_t+\frac{\sqrt{\overline{\alpha_{t-1}}}\beta_t}{1-\overline{\alpha_t}}x_0 \\
\sigma^2=\frac{1-\overline{\alpha_{t-1}}}{1-\overline{\alpha_t}}\beta_t
$$</p><p>但实际上我们需要通过神经网络来训练出一个分布$p_{\theta}(x_{t-1}|x_t)$，该分布的均值和方差均是含参数的，即上述的$\mu_{\theta}(x_t,t)$与$\Sigma_{\theta}(x_t,t)$。我们考虑使用$q(x_{t-1}|x_t,x_0)$来近似估计$p_{\theta}(x_{t-1}|x_t)$，这显然是可行的，因为$x_t$可以由$x_0$来表示，同理也可以使用$x_t$来表示$x_0$。综上可得以下关于均值和方差的表达式：</p><p>$$
\mu_{\theta}(x_t,t)=\frac{\sqrt{\alpha_t}(1-\overline{\alpha_{t-1}})}{1-\overline{\alpha_{t}}}x_t+\frac{\sqrt{\overline{\alpha_{t-1}}}\beta_t}{1-\overline{\alpha_t}}x_0 \\
\Sigma_{\theta}(x_t,t)=\frac{1-\overline{\alpha_{t-1}}}{1-\overline{\alpha_t}}\beta_t
$$</p><p>对于其中出现的先验知识$x_0$，考虑使用$x_t$来表达，即有：
$$
x_0=\frac{x_t-\sqrt{1-\overline{\alpha_t}}z}{\sqrt{\overline{\alpha_t}}}
$$
代入均值$\mu_{\theta}(x_t,t)$的表达式，有以下推导过程：</p><p>$$
\begin{aligned}
\mu_{\theta}(x_t,t)&=\frac{\sqrt{\alpha_t}(1-\overline{\alpha_{t-1}})}{1-\overline{\alpha_{t}}}x_t+\frac{\sqrt{\overline{\alpha_{t-1}}}\beta_t}{1-\overline{\alpha_t}}x_0 \\
&=\frac{\sqrt{\alpha_t}(1-\overline{\alpha_{t-1}})}{1-\overline{\alpha_{t}}}x_t+\frac{\sqrt{\overline{\alpha_{t-1}}}\beta_t}{1-\overline{\alpha_t}}\frac{x_t-\sqrt{1-\overline{\alpha_t}}z}{\sqrt{\overline{\alpha_t}}} \\
&=\frac{1}{\sqrt{\alpha_t}}(x_t-\frac{1-\alpha_t}{\sqrt{1-\overline{\alpha_t}}}z)
\end{aligned}
$$</p><p>观察表达式可以发现，$\alpha_t$、$x_t$、$\overline{\alpha_t}$均为已知量，模型需要确定$\mu_{\theta}(x_t,t)$，本质上是个噪声预测的过程，即对于上式中的$z$，需要交给神经网络去预测，记为$z_{\theta}(x_t,t)$。</p><p>综上，反向去噪过程可以概括为：</p><ol><li>根据$x_t$和$t$预测高斯噪声$z_{\theta}(x_t,t)$，则能够得到模型预测的去噪后的分布均值$\mu_{\theta}(x_t,t)$，其实就是去噪后的图像。</li><li>得到方差$\Sigma_{\theta}(x_t,t)$，在DDPM中方差是untrained的，即$\Sigma_{\theta}(x_t,t)=\frac{1-\overline{\alpha_{t-1}}}{1-\overline{\alpha_t}}\beta_t$，但对于方差也可以进行训练估计。</li><li>$p_{\theta}(x_{t-1}|x_t)=\mathcal N (x_{t-1};\mu_{\theta}(x_t,t),\Sigma_{\theta}(x_t,t))$进行去噪，获得$x_{t-1}$，通过重参数技巧。</li></ol><h3 id=3-训练方式与策略>3. 训练方式与策略</h3><h4 id=常规的训练流程>常规的训练流程</h4><ol><li>从数据集中采样得到$x_0$，$x_0 \sim q(x)$，并在$1&mldr;T$中随机采样一个 $t$。</li><li>从标准高斯分布中采样一个噪声$z\sim \mathcal N (0,\mathbf{I})$。</li><li>根据重参数技巧得到$x_t=\sqrt{\overline{\alpha_t}}x_0+\sqrt{1-\overline{\alpha_t}}z$。</li><li>训练UNet，输入$x_t$和$t$，模型输出$z_{\theta}(x_t,t)$，将$z_{\theta}(x_t,t)$和$z$做Loss。</li></ol><h4 id=推理流程>推理流程</h4><ol><li>从标准高斯分布中采样得到一个噪声$x_t \sim \mathcal N(0,\mathbf{I})$。</li><li>从$T$到1遍历变量$t$，如果$t==1$则$z=0$，否则采样噪声$z\sim\mathcal N(0,\mathbf{I})$。</li><li>UNet推理得到$z_\theta(x_t,t)$，进行去噪$x_{t-1}=\frac{1}{\sqrt{\overline{\alpha_t}}}(x_t-\frac{1-\alpha_t}{\sqrt{1-\overline{\alpha_t}}}z_{\theta}(x_t,t))+\Sigma_{\theta}(x_t,t)z$。</li><li>得到$x_0$。</li></ol><h3 id=4-diffusion的应用拓展>4. Diffusion的应用拓展</h3><h4 id=diffusion做分割segdiff>Diffusion做分割（SegDiff）</h4><p><img alt=image-1 src=/images/diffusion/image-1.png></p><p>要点：将待分割图像作为condition image进行特征的提取，在进入UNet之前进行特征的融合，扩散生成的为mask。</p><p>训练$\mu_{\theta}(x_t,t)$时，需要加入图像的特征，即$\mu_{\theta}(x_t,t,I)$，推理时同理。</p><script type=text/javascript async src="https://cdn.bootcss.com/mathjax/2.7.3/MathJax.js?config=TeX-AMS-MML_HTMLorMML">MathJax.Hub.Config({tex2jax:{inlineMath:[["$","$"],["\\(","\\)"]],displayMath:[["$$","$$"],["[[","]]"]],processEscapes:!0,processEnvironments:!0,skipTags:["script","noscript","style","textarea","pre"],TeX:{equationNumbers:{autoNumber:"AMS"},extensions:["AMSmath.js","AMSsymbols.js"]}}}),MathJax.Hub.Queue(function(){var e,t=MathJax.Hub.getAllJax();for(e=0;e<t.length;e+=1)t[e].SourceElement().parentNode.className+=" has-jax"})</script><style>code.has-jax{font:inherit;font-size:100%;background:inherit;border:inherit;color:#515151}</style></div><div class="row items-start justify-between"><div class="lg:col-5 mb-10 flex items-center lg:mb-0"><h5 class=mr-3>标签 :</h5><ul><li class=inline-block><a class="bg-theme-light hover:bg-primary dark:bg-darkmode-theme-light dark:hover:bg-darkmode-primary dark:hover:text-dark m-1 block rounded px-3 py-1 hover:text-white" href=/en/tags/%e6%89%a9%e6%95%a3%e6%a8%a1%e5%9e%8b/>扩散模型</a></li><li class=inline-block><a class="bg-theme-light hover:bg-primary dark:bg-darkmode-theme-light dark:hover:bg-darkmode-primary dark:hover:text-dark m-1 block rounded px-3 py-1 hover:text-white" href=/en/tags/%e5%9b%be%e5%83%8f%e7%94%9f%e6%88%90/>图像生成</a></li></ul></div></div></article></div></div></section></main><footer class="bg-theme-light dark:bg-darkmode-theme-light"><div class=container><div class="row items-center py-10"><div class="lg:col-3 mb-8 text-center lg:mb-0 lg:text-left"><a class="navbar-brand inline-block" href=/en/><img fetchpriority=high decoding=async class="img logo-light" width=160 height=32 src=/images/logo-1_hubf409f6fc77577ff09f7cacc73653041_8513_320x0_resize_q80_h2_lanczos_3.webp alt=Hugoplate onerror='this.onerror=null,this.src="/images/logo-1_hubf409f6fc77577ff09f7cacc73653041_8513_320x0_resize_lanczos_3.png"'>
<img fetchpriority=high decoding=async class="img logo-dark" width=160 height=32 src=/images/logo-2_hu06a606f114baa5722e40403b02652855_7961_320x0_resize_q80_h2_lanczos_3.webp alt=Hugoplate onerror='this.onerror=null,this.src="/images/logo-2_hu06a606f114baa5722e40403b02652855_7961_320x0_resize_lanczos_3.png"'></a></div><div class="lg:col-6 mb-8 text-center lg:mb-0"><ul><li class="m-3 inline-block"><a href=/en/about/>个人信息</a></li><li class="m-3 inline-block"><a href=/en/blog/>学习笔记</a></li><li class="m-3 inline-block"><a href=/en/privacy-policy/>相关说明</a></li></ul></div><div class="lg:col-3 mb-8 text-center lg:mb-0 lg:mt-0 lg:text-right"><ul class=social-icons><li><a target=_blank aria-label=github rel="nofollow noopener" href=https://www.github.com/COOOIKX><i class="fab fa-github"></i></a></li><li><a target=_blank aria-label=csdn rel="nofollow noopener" href="https://blog.csdn.net/m0_59701064?spm=1000.2115.3001.5343"><i class="fas fa-home-lg"></i></a></li></ul></div></div></div><div class="border-border dark:border-darkmode-border border-t py-7"><div class="text-light dark:text-darkmode-light container text-center"><p>Designed by Zeon Studio and Developed by LHF</p></div></div></footer><script crossorigin=anonymous integrity="sha256-YQerunHGeT7hXzxweSqFUXgOHHxFceSjmMy/kmnAHWU=" src=/js/script.min.6107abba71c6793ee15f3c70792a8551780e1c7c4571e4a398ccbf9269c01d65.js></script><script defer async crossorigin=anonymous integrity="sha256-w+aS42D2+B+Jix+joZ7pAua1vbu/pRK/IhoP55b8n3w=" src=/js/script-lazy.min.c3e692e360f6f81f898b1fa3a19ee902e6b5bdbbbfa512bf221a0fe796fc9f7c.js></script><script>"serviceWorker"in navigator&&navigator.serviceWorker.register("/service-worker.js")</script></body></html>