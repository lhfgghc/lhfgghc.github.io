<!doctype html><html itemscope lang=en-us itemtype=http://schema.org/WebPage><head><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1,maximum-scale=5"><meta name=theme-name content="hugoplate"><link rel="shortcut icon" href=/images/favicon_hueb84ecec72665a83aae8c940dfe71474_1906_96x0_resize_lanczos_3.png type=image/x-icon><link rel=icon href=/images/favicon_hueb84ecec72665a83aae8c940dfe71474_1906_96x0_resize_lanczos_3.png type=image/x-icon><link rel=icon type=image/png sizes=48x48 href=/images/favicon_hueb84ecec72665a83aae8c940dfe71474_1906_48x0_resize_lanczos_3.png><link rel=icon type=image/png sizes=96x96 href=/images/favicon_hueb84ecec72665a83aae8c940dfe71474_1906_96x0_resize_lanczos_3.png><link rel=apple-touch-icon sizes=144x144 href=/images/favicon_hueb84ecec72665a83aae8c940dfe71474_1906_144x0_resize_lanczos_3.png><link rel=manifest href=/manifest.webmanifest><meta name=msapplication-TileColor content="#ddd"><meta name=theme-color content="#ffffff"><base href=https://lhfgghc.github.io/en/blog/lossfunction/><title>【泛学内容】损失函数相关</title>
<meta name=keywords content="Boilerplate,Hugo"><meta name=description content="this is meta description"><meta name=author content="zeon.studio"><meta property="og:image" content="https://lhfgghc.github.io/images/lossfunction/focalloss.png"><meta name=twitter:image content="https://lhfgghc.github.io/images/lossfunction/focalloss.png"><meta name=twitter:card content="summary_large_image"><meta property="og:image:width" content="809"><meta property="og:image:height" content="475"><meta property="og:image:type" content="image/
        .png
      "><meta property="og:title" content="【泛学内容】损失函数相关"><meta property="og:description" content="this is meta description"><meta property="og:type" content="website"><meta property="og:url" content="https://lhfgghc.github.io/en/blog/lossfunction/"><meta name=twitter:title content="【泛学内容】损失函数相关"><meta name=twitter:description content="this is meta description"><script>let indexURL="https://lhfgghc.github.io/en/searchindex.json",includeSectionsInSearch=["blog"],search_no_results="未找到结果",search_initial_message="输入内容以搜索"</script><meta http-equiv=x-dns-prefetch-control content="on"><link rel=preconnect href=https://use.fontawesome.com crossorigin><link rel=preconnect href=//cdnjs.cloudflare.com><link rel=preconnect href=//www.googletagmanager.com><link rel=preconnect href=//www.google-analytics.com><link rel=dns-prefetch href=https://use.fontawesome.com><link rel=dns-prefetch href=//ajax.googleapis.com><link rel=dns-prefetch href=//cdnjs.cloudflare.com><link rel=dns-prefetch href=//www.googletagmanager.com><link rel=dns-prefetch href=//www.google-analytics.com><link rel=dns-prefetch href=//fonts.googleapis.com><link rel=dns-prefetch href=//connect.facebook.net><link rel=dns-prefetch href=//platform.linkedin.com><link rel=dns-prefetch href=//platform.twitter.com><link rel=preconnect href=https://fonts.googleapis.com><link rel=preconnect href=https://fonts.gstatic.com crossorigin><script>(function(){const e=document.createElement("link");e.href="https://fonts.googleapis.com/css2?family=Heebo:wght@400;600&family=Signika:wght@500;700&display=swap",e.type="text/css",e.rel="stylesheet",document.head.appendChild(e)})()</script><link href="/css/style.min.713df11224e9a4dbafb778a70125ddfd6f9cbab0d41fd212d8fa2eddfd5892b3.css" integrity="sha256-cT3xEiTppNuvt3inASXd/W+curDUH9IS2Pou3f1YkrM=" rel=stylesheet><link defer async rel=stylesheet href="/css/style-lazy.min.ec14d2549e8e0fbaf9af20dcc88fad37fb352e5bd5978a801dc1c3f5a5922174.css" integrity="sha256-7BTSVJ6OD7r5ryDcyI+tN/s1LlvVl4qAHcHD9aWSIXQ=" media=print onload='this.media="all",this.onload=null'></head><body><header class="header sticky top-0 z-30"><nav class="navbar container"><div class=order-0><a class="navbar-brand block" href=/en/><img fetchpriority=high decoding=async class="img logo-light" width=160 height=32 src=/images/logo_hud3822dc52499c854acb9b180fed4f736_3648_320x0_resize_q80_h2_lanczos_3.webp alt=Hugoplate onerror='this.onerror=null,this.src="/images/logo_hud3822dc52499c854acb9b180fed4f736_3648_320x0_resize_lanczos_3.png"'>
<img fetchpriority=high decoding=async class="img logo-dark" width=160 height=32 src=/images/logo-darkmode_hu95dd250582672ebe0c063cf60eed448f_3090_320x0_resize_q80_h2_lanczos_3.webp alt=Hugoplate onerror='this.onerror=null,this.src="/images/logo-darkmode_hu95dd250582672ebe0c063cf60eed448f_3090_320x0_resize_lanczos_3.png"'></a></div><input id=nav-toggle type=checkbox class=hidden>
<label for=nav-toggle class="order-3 cursor-pointer flex items-center lg:hidden text-dark dark:text-white lg:order-1"><svg id="show-button" class="h-6 fill-current block" viewBox="0 0 20 20"><title>Menu Open</title><path d="M0 3h20v2H0V3zm0 6h20v2H0V9zm0 6h20v2H0V0z"/></svg><svg id="hide-button" class="h-6 fill-current hidden" viewBox="0 0 20 20"><title>Menu Close</title><polygon points="11 9 22 9 22 11 11 11 11 22 9 22 9 11 -2 11 -2 9 9 9 9 -2 11 -2" transform="rotate(45 10 10)"/></svg></label><ul id=nav-menu class="navbar-nav order-3 hidden lg:flex w-full pb-6 lg:order-1 lg:w-auto lg:space-x-2 lg:pb-0 xl:space-x-8"><li class=nav-item><a class=nav-link href=/en/>主页</a></li><li class=nav-item><a class=nav-link href=/en/about/>个人信息</a></li><li class=nav-item><a class=nav-link href=/en/blog/>学习笔记</a></li><li class="nav-item nav-dropdown group relative"><span class="nav-link
inline-flex items-center">Pages<svg class="h-4 w-4 fill-current" viewBox="0 0 20 20"><path d="M9.293 12.95l.707.707L15.657 8l-1.414-1.414L10 10.828 5.757 6.586 4.343 8z"/></svg></span><ul class="nav-dropdown-list lg:group-hover:visible lg:group-hover:opacity-100"><li class=nav-dropdown-item><a class=nav-dropdown-link href=/en/404.html>404 Page</a></li><li class=nav-dropdown-item><a class=nav-dropdown-link href=/en/authors/>Authors</a></li><li class=nav-dropdown-item><a class=nav-dropdown-link href=/en/blog/>Blog</a></li><li class=nav-dropdown-item><a class=nav-dropdown-link href=/en/contact/>Contact</a></li><li class=nav-dropdown-item><a class=nav-dropdown-link href=/en/elements/>Elements</a></li><li class=nav-dropdown-item><a class=nav-dropdown-link href=/en/categories/>分类</a></li></ul></li></ul><div class="order-1 ml-auto flex items-center md:order-2 lg:ml-0"><button aria-label=search class="border-border text-dark hover:text-primary dark:border-darkmode-border mr-5 inline-block border-r pr-5 text-xl dark:text-white dark:hover:text-darkmode-primary" data-target=search-modal>
<i class="fa-solid fa-search"></i></button><div class="theme-switcher mr-5"><input id=theme-switcher data-theme-switcher type=checkbox>
<label for=theme-switcher><span class=sr-only>theme switcher</span>
<span><svg class="absolute left-1/2 top-1/2 -translate-x-1/2 -translate-y-1/2 z-10 opacity-100 dark:opacity-0" viewBox="0 0 56 56" fill="#fff" height="16" width="16"><path d="M30 4.6c0-1-.9-2-2-2a2 2 0 00-2 2v5c0 1 .9 2 2 2s2-1 2-2zm9.6 9a2 2 0 000 2.8c.8.8 2 .8 2.9.0L46 13a2 2 0 000-2.9 2 2 0 00-3 0zm-26 2.8c.7.8 2 .8 2.8.0.8-.7.8-2 0-2.9L13 10c-.7-.7-2-.8-2.9.0-.7.8-.7 2.1.0 3zM28 16A12 12 0 0016 28a12 12 0 0012 12 12 12 0 0012-12A12 12 0 0028 16zm23.3 14c1.1.0 2-.9 2-2s-.9-2-2-2h-4.9a2 2 0 00-2 2c0 1.1 1 2 2 2zM4.7 26a2 2 0 00-2 2c0 1.1.9 2 2 2h4.9c1 0 2-.9 2-2s-1-2-2-2zm37.8 13.6a2 2 0 00-3 0 2 2 0 000 2.9l3.6 3.5a2 2 0 002.9.0c.8-.8.8-2.1.0-3zM10 43.1a2 2 0 000 2.9c.8.7 2.1.8 3 0l3.4-3.5c.8-.8.8-2.1.0-2.9s-2-.8-2.9.0zm20 3.4c0-1.1-.9-2-2-2a2 2 0 00-2 2v4.9c0 1 .9 2 2 2s2-1 2-2z"/></svg><svg class="absolute left-1/2 top-1/2 -translate-x-1/2 -translate-y-1/2 z-10 opacity-0 dark:opacity-100" viewBox="0 0 24 24" fill="none" height="16" width="16"><path fill="#000" fill-rule="evenodd" clip-rule="evenodd" d="M8.2 2.2c1-.4 2 .6 1.6 1.5-1 3-.4 6.4 1.8 8.7a8.4 8.4.0 008.7 1.8c1-.3 2 .5 1.5 1.5v.1A10.3 10.3.0 0112.4 22 10.3 10.3.0 013.2 6.7c1-2 2.9-3.5 4.9-4.4z"/></svg></span></label></div><script>var darkMode=!1,themeSwitch;window.matchMedia("(prefers-color-scheme: dark)").matches&&(darkMode=!0),localStorage.getItem("theme")==="dark"?darkMode=!0:localStorage.getItem("theme")==="light"&&(darkMode=!1),darkMode&&document.documentElement.classList.toggle("dark"),themeSwitch=document.querySelectorAll("[data-theme-switcher]"),document.addEventListener("DOMContentLoaded",()=>{[].forEach.call(themeSwitch,function(e){e.checked=!!darkMode,e.addEventListener("click",()=>{document.documentElement.classList.toggle("dark"),localStorage.setItem("theme",document.documentElement.classList.contains("dark")?"dark":"light")})})})</script></div></nav></header><div class=search-modal aria-hidden=true style=--color-primary:#121212><div data-target=close-search-modal class=search-modal-overlay></div><div class=search-wrapper data-image=true data-description=true data-tags=true data-categories=true><div class=search-wrapper-header><label for=search-modal-input style=margin-top:-1px><span class=sr-only>search icon</span>
<svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512" height="18" width="18" class="search-icon" data-type="search"><path fill="currentcolor" d="M416 208c0 45.9-14.9 88.3-40 122.7L502.6 457.4c12.5 12.5 12.5 32.8.0 45.3s-32.8 12.5-45.3.0L330.7 376c-34.4 25.2-76.8 40-122.7 40C93.1 416 0 322.9.0 208S93.1.0 208 0 416 93.1 416 208zM208 352a144 144 0 100-288 144 144 0 100 288z"/></svg>
<svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512" height="18" width="18" class="search-reset" data-type="reset"><path fill="currentcolor" d="M256 512A256 256 0 10256 0a256 256 0 100 512zM175 175c9.4-9.4 24.6-9.4 33.9.0l47 47 47-47c9.4-9.4 24.6-9.4 33.9.0s9.4 24.6.0 33.9l-47 47 47 47c9.4 9.4 9.4 24.6.0 33.9s-24.6 9.4-33.9.0l-47-47-47 47c-9.4 9.4-24.6 9.4-33.9.0s-9.4-24.6.0-33.9l47-47-47-47c-9.4-9.4-9.4-24.6.0-33.9z"/></svg>
</label><input id=search-modal-input type=text data-search-input autocomplete=off aria-label=Search placeholder=搜索></div><div class=search-wrapper-body><div class=search-result data-search-result></div><span class=search-result-empty>输入内容以搜索</span></div><div class=search-wrapper-footer><span><kbd><svg xmlns="http://www.w3.org/2000/svg" width="14" height="14" fill="currentcolor" viewBox="0 0 16 16"><path d="M3.204 11h9.592L8 5.519 3.204 11zm-.753-.659 4.796-5.48a1 1 0 011.506.0l4.796 5.48c.566.647.106 1.659-.753 1.659H3.204a1 1 0 01-.753-1.659z"/></svg>
</kbd><kbd><svg xmlns="http://www.w3.org/2000/svg" width="14" height="14" fill="currentcolor" style="margin-top:1px" viewBox="0 0 16 16"><path d="M3.204 5h9.592L8 10.481 3.204 5zm-.753.659 4.796 5.48a1 1 0 001.506.0l4.796-5.48c.566-.647.106-1.659-.753-1.659H3.204a1 1 0 00-.753 1.659z"/></svg>
</kbd>导航
</span><span><kbd><svg xmlns="http://www.w3.org/2000/svg" width="12" height="12" fill="currentcolor" style="display:inline-block" viewBox="0 0 16 16"><path fill-rule="evenodd" d="M14.5 1.5a.5.5.0 01.5.5v4.8a2.5 2.5.0 01-2.5 2.5H2.707l3.347 3.346a.5.5.0 01-.708.708l-4.2-4.2a.5.5.0 010-.708l4-4a.5.5.0 11.708.708L2.707 8.3H12.5A1.5 1.5.0 0014 6.8V2a.5.5.0 01.5-.5z"/></svg>
</kbd>选择
</span><span class=search-result-info></span>
<span data-target=close-search-modal><kbd>ESC</kbd> 关闭</span></div></div></div><main><section class="section pt-7"><div class=container><div class="row justify-center"><article class=lg:col-10><div class=mb-10><picture><source srcset=/images/lossfunction/focalloss_hu32ecab99632a1940dcc8620954844b12_118544_545x0_resize_q80_h2_lanczos_3.webp media="(max-width: 575px)"><source srcset=/images/lossfunction/focalloss_hu32ecab99632a1940dcc8620954844b12_118544_600x0_resize_q80_h2_lanczos_3.webp media="(max-width: 767px)"><source srcset=/images/lossfunction/focalloss_hu32ecab99632a1940dcc8620954844b12_118544_700x0_resize_q80_h2_lanczos_3.webp media="(max-width: 991px)"><source srcset=/images/lossfunction/focalloss_hu32ecab99632a1940dcc8620954844b12_118544_1110x0_resize_q80_h2_lanczos_3.webp><img loading=lazy decoding=async src=/images/lossfunction/focalloss_hu32ecab99632a1940dcc8620954844b12_118544_1110x0_resize_lanczos_3.png class="w-full rounded img" alt=【泛学内容】损失函数相关 width=809 height=475></picture></div><h1 class="h2 mb-4">【泛学内容】损失函数相关</h1><ul class=mb-4><li class="mr-4 inline-block"><a href=/en/authors/liang-hangfeng/><i class="fa-regular fa-circle-user mr-2"></i>Liang Hangfeng</a></li><li class="mr-4 inline-block"><i class="fa-regular fa-folder mr-2"></i>
<a href=/en/categories/%e6%b7%b1%e5%ba%a6%e5%ad%a6%e4%b9%a0/>深度学习
,
</a><a href=/en/categories/%e6%b3%9b%e5%ad%a6%e5%86%85%e5%ae%b9/>泛学内容</a></li><li class="mr-4 inline-block"><i class="fa-regular fa-clock mr-2"></i>
January 14, 2024</li></ul><div class="content mb-10"><h3 id=损失函数loss-function>损失函数Loss Function</h3><h4 id=一回归任务常用loss>一、回归任务常用Loss</h4><h5 id=1-l1-loss>1. L1 Loss</h5><h6 id=原理>原理</h6><p>即为平均绝对值误差MAE，主要用于简单的回归问题，指模型预测值与真实值之间的绝对差值的平均值。</p><h6 id=表达式>表达式</h6><p>$$
MAE=\frac{1}{n}\sum_{i=1}^{n}|f(x_i)-y_i|
$$</p><h6 id=代码>代码</h6><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span>criterion <span style=color:#f92672>=</span> nn<span style=color:#f92672>.</span>L1Loss()
</span></span><span style=display:flex><span>loss <span style=color:#f92672>=</span> criterion(target, pred)
</span></span></code></pre></div><h5 id=2-mse-loss>2. MSE Loss</h5><h6 id=原理-1>原理</h6><p>均方误差损失函数MSE，指模型预测值与真实值之间的差的平方的平均值。</p><h6 id=表达式-1>表达式</h6><p>$$
MSE=\frac{1}{n}\sum_{i=1}^{n}(f(x_i)-y_i)^2
$$</p><h6 id=代码-1>代码</h6><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span>criterion <span style=color:#f92672>=</span> nn<span style=color:#f92672>.</span>MSELoss()
</span></span><span style=display:flex><span>loss <span style=color:#f92672>=</span> criterion(target, pred)
</span></span></code></pre></div><h6 id=备注>备注</h6><p>reduce参数取值：</p><p>none：维度不缩减，返回相同shape的结果，每个位置均为对应元素差值的平方</p><p>mean：默认值，所有位置的损失取平均</p><p>sum：所有位置的损失求和但不取平均</p><p>与L2Loss的关系：</p><p>在大多数情况下是同一个概念，但严格来说L2Loss对平方和求得结果后会进一步求平方根。</p><h4 id=二分类任务常用loss>二、分类任务常用Loss</h4><h5 id=1-nllloss>1. NLLLoss</h5><h6 id=原理-2>原理</h6><p>即为负对数似然函数，常用于多分类。取对应位置的数值进行相加即可，最后取负值。</p><h6 id=表达式-2>表达式</h6><p>$$
Loss=-\sum_iy_if(x_i)
$$</p><h6 id=代码-2>代码</h6><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span>criterion <span style=color:#f92672>=</span> nn<span style=color:#f92672>.</span>NLLLoss()
</span></span><span style=display:flex><span>loss <span style=color:#f92672>=</span> criterion(target, pred)
</span></span></code></pre></div><h6 id=备注-1>备注</h6><p>这里的target可以传入索引，Pytorch实现的函数内进行了one-hot</p><p>对于pred的内容需要进行softmax+log操作</p><h5 id=2-bceloss>2. BCELoss</h5><h6 id=原理-3>原理</h6><p>即为二值交叉熵损失，适用于0/1的二值分类，模型输出一个概率值，即为预测为正例的概率。</p><h6 id=表达式-3>表达式</h6><p>$$
BCE = -\frac{1}{n}\sum_i(y_i.log(f(x_i))+(1-y_i).log(1-f(x_i)))
$$</p><h6 id=代码-3>代码</h6><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span>criterion <span style=color:#f92672>=</span> nn<span style=color:#f92672>.</span>BCELoss()
</span></span><span style=display:flex><span>loss <span style=color:#f92672>=</span> criterion(target, pred)
</span></span></code></pre></div><h5 id=3-crossentropyloss>3. CrossEntropyLoss</h5><h6 id=原理-4>原理</h6><p>即为交叉熵损失，适用于多分类问题</p><h6 id=表达式-4>表达式</h6><p>$$
Loss=-\sum_iy_ilog(f(x_i))
$$</p><h6 id=代码-4>代码</h6><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span>criterion <span style=color:#f92672>=</span> nn<span style=color:#f92672>.</span>CrossEntropyLoss()
</span></span><span style=display:flex><span>loss <span style=color:#f92672>=</span> criterion(target, pred)
</span></span></code></pre></div><h6 id=备注-2>备注</h6><p>nn.CrossEntropyLoss()结合了nn.LogSoftmax()和nn.NLLLoss()函数，前者经过softmax后取对数。</p><p>其中target是真实标签，每个元素的值是样本所属类别的索引值</p><p>形式上与负对数似然损失类似，但负对数似然函数是基于极大似然估计的概率方法，但交叉熵是信息论种将两个概率分布进行差异性分析的方式，本质有所差别。</p><h5 id=4-dice>4. Dice</h5><h6 id=原理-5>原理</h6><p>Dice Loss由Dice系数而来，Dice系数是用来描述两个样本相似性的函数，值越大则越相似，那么对应的Loss就可以是1-Dice系数。</p><h6 id=表达式-5>表达式</h6><p>$$
DiceLoss=1-\frac{2|X \cap Y}{|X|+|Y|}
$$</p><h6 id=代码-5>代码</h6><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#66d9ef>class</span> <span style=color:#a6e22e>DiceLoss</span>(nn<span style=color:#f92672>.</span>Module):
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>def</span> __init__(self):
</span></span><span style=display:flex><span>        super()<span style=color:#f92672>.</span>__init__()
</span></span><span style=display:flex><span>        self<span style=color:#f92672>.</span>epsilon <span style=color:#f92672>=</span> <span style=color:#ae81ff>1e-5</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>def</span> <span style=color:#a6e22e>forward</span>(self, output, target):
</span></span><span style=display:flex><span>        <span style=color:#66d9ef>assert</span> output<span style=color:#f92672>.</span>size() <span style=color:#f92672>==</span> target<span style=color:#f92672>.</span>size()
</span></span><span style=display:flex><span>        output <span style=color:#f92672>=</span> F<span style=color:#f92672>.</span>softmax(output, dim<span style=color:#f92672>=</span><span style=color:#ae81ff>1</span>)
</span></span><span style=display:flex><span>        output <span style=color:#f92672>=</span> flatten(output)
</span></span><span style=display:flex><span>        target <span style=color:#f92672>=</span> flatten(target)
</span></span><span style=display:flex><span>        intersect <span style=color:#f92672>=</span> (output <span style=color:#f92672>*</span> target)<span style=color:#f92672>.</span>sum(<span style=color:#f92672>-</span><span style=color:#ae81ff>1</span>)
</span></span><span style=display:flex><span>        denominator <span style=color:#f92672>=</span> (output <span style=color:#f92672>+</span> target)<span style=color:#f92672>.</span>sum(<span style=color:#f92672>-</span><span style=color:#ae81ff>1</span>)
</span></span><span style=display:flex><span>        dice <span style=color:#f92672>=</span> intersect <span style=color:#f92672>/</span> denominator
</span></span><span style=display:flex><span>        dice <span style=color:#f92672>=</span> torch<span style=color:#f92672>.</span>mean(dice)
</span></span><span style=display:flex><span>        <span style=color:#66d9ef>return</span> <span style=color:#ae81ff>1</span> <span style=color:#f92672>-</span> dice
</span></span></code></pre></div><h5 id=5-focal-loss>5. Focal Loss</h5><h6 id=原理-6>原理</h6><p>Focal Loss是由交叉熵演变而来，对于一些样本分布及其不均匀的分割任务，例如血管分割，使用BCELoss容易产生初始状态下Loss就已经很小的情况。</p><p>因此引入来控制正负样本的loss权重，例如引入一个$\alpha_t$，当真实为正样例时，取值为$\alpha$，反之为$1-\alpha$，并将其架在原有的交叉熵损失上，记当为真实为正例时$p_t=p$，反之$p_t=1-p$，相当于模型输出的p为预测为正例的概率。</p><p>因此交叉熵损失更改为$-\alpha_tlog(p_t)$，若$\alpha$取值较小，当遇到正例时对损失函数带来的Loss影响更大（因为有负号的存在），反之负例则Loss影响较小。</p><p>但这并不能使得模型聚焦于hard样例的学习，引入调制因子$(1-p_t)^\gamma$，对于正例，若模型输出的结果较小，认定其具有学习难度，结果$p_t$越小，难度越大，调制因子带来的Loss就越大。</p><h6 id=表达式-6>表达式</h6><p>最终表达式如下：</p><p>$$
Focal=\left\{
\begin{aligned}
-(1-\alpha)f(x)^\gamma log(1-f(x)), \ y=0 \\
-\alpha (1-f(x))^\gamma log(f(x)),\ y=1
\end{aligned}
\right.
$$</p><h6 id=代码-6>代码</h6><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#66d9ef>class</span> <span style=color:#a6e22e>WeightedFocalLoss</span>(nn<span style=color:#f92672>.</span>Module):
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>def</span> __init__(self, alpha<span style=color:#f92672>=</span><span style=color:#ae81ff>.25</span>, gamma<span style=color:#f92672>=</span><span style=color:#ae81ff>2</span>):
</span></span><span style=display:flex><span>        super(WeightedFocalLoss, self)<span style=color:#f92672>.</span>__init__()
</span></span><span style=display:flex><span>        self<span style=color:#f92672>.</span>gamma <span style=color:#f92672>=</span> gamma
</span></span><span style=display:flex><span>        self<span style=color:#f92672>.</span>alpha <span style=color:#f92672>=</span> alpha
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>def</span> <span style=color:#a6e22e>forward</span>(self, inputs, targets):
</span></span><span style=display:flex><span>        BCE_loss <span style=color:#f92672>=</span> F<span style=color:#f92672>.</span>binary_cross_entropy_with_logits(inputs, targets, reduction<span style=color:#f92672>=</span><span style=color:#e6db74>&#39;none&#39;</span>)
</span></span><span style=display:flex><span>        pt <span style=color:#f92672>=</span> torch<span style=color:#f92672>.</span>exp(<span style=color:#f92672>-</span>BCE_loss)
</span></span><span style=display:flex><span>        F_loss <span style=color:#f92672>=</span> self<span style=color:#f92672>.</span>alpha <span style=color:#f92672>*</span> (<span style=color:#ae81ff>1</span> <span style=color:#f92672>-</span> pt) <span style=color:#f92672>**</span> self<span style=color:#f92672>.</span>gamma <span style=color:#f92672>*</span> BCE_loss
</span></span><span style=display:flex><span>        <span style=color:#66d9ef>return</span> F_loss<span style=color:#f92672>.</span>mean()
</span></span></code></pre></div><h6 id=备注-3>备注</h6><p>对于$\alpha$和$\gamma$的取值，通常为0.25和2。</p><p>实验效果不佳？对于非小比例正例的训练情况</p><h4 id=三其它loss>三、其它Loss</h4><h5 id=1-kl散度>1. KL散度</h5><h6 id=原理-7>原理</h6><p>信息熵的定义：</p><p>一个事件信息量的期望，形式上：设事件$X$有$n$种可能，发生$x_i$的概率为$p(x_i)$，则该事件的熵$H(X)$则为：
$$
H(x)=-\sum_{i=1}^{n}p(x_i)log(p(x_i))
$$
相对熵的定义：</p><p>对于同一个随机变量$$x$$有两个单独的概率分布$P(x)$和$Q(x)$，使用KL散度描述差异，其中$P$往往是真实分布，$Q$为模型所预测的分布。</p><h6 id=表达式-7>表达式</h6><p>$$
D_{KL}(p||q)=\sum_{i=1}^{n}[p(x_i)log(p(x_i))-p(x_i)log(q(x_i))]=\sum_{i=1}^{n}p(x_i)log(\frac{p(x_i)}{q(x_i)})
$$</p><h6 id=备注-4>备注</h6><p>KL散度可以理解为从A角度来看，B事件和A事件的差异性。</p><h5 id=2-hinge损失>2. Hinge损失</h5><h6 id=原理-8>原理</h6><p>常用于SVM中，二分类问题，对于标签值$y \in { 1,-1 }$，预测值$\hat{y} \in R$，当预测值在$(-1,1)$之外时，分类结果确定，反之分类结果不确定，loss不为0，当预测值为0时，显然loss是最大的。Loss向零线性增长。</p><h6 id=表达式-8>表达式</h6><p>$$
Hinge=max(0,1-yf(x))
$$</p><script type=text/javascript async src="https://cdn.bootcss.com/mathjax/2.7.3/MathJax.js?config=TeX-AMS-MML_HTMLorMML">MathJax.Hub.Config({tex2jax:{inlineMath:[["$","$"],["\\(","\\)"]],displayMath:[["$$","$$"],["[[","]]"]],processEscapes:!0,processEnvironments:!0,skipTags:["script","noscript","style","textarea","pre"],TeX:{equationNumbers:{autoNumber:"AMS"},extensions:["AMSmath.js","AMSsymbols.js"]}}}),MathJax.Hub.Queue(function(){var e,t=MathJax.Hub.getAllJax();for(e=0;e<t.length;e+=1)t[e].SourceElement().parentNode.className+=" has-jax"})</script><style>code.has-jax{font:inherit;font-size:100%;background:inherit;border:inherit;color:#515151}</style></div><div class="row items-start justify-between"><div class="lg:col-5 mb-10 flex items-center lg:mb-0"><h5 class=mr-3>标签 :</h5><ul><li class=inline-block><a class="bg-theme-light hover:bg-primary dark:bg-darkmode-theme-light dark:hover:bg-darkmode-primary dark:hover:text-dark m-1 block rounded px-3 py-1 hover:text-white" href=/en/tags/%e6%8d%9f%e5%a4%b1%e5%87%bd%e6%95%b0/>损失函数</a></li><li class=inline-block><a class="bg-theme-light hover:bg-primary dark:bg-darkmode-theme-light dark:hover:bg-darkmode-primary dark:hover:text-dark m-1 block rounded px-3 py-1 hover:text-white" href=/en/tags/%e5%ae%9e%e9%aa%8c%e8%ae%b0%e5%bd%95/>实验记录</a></li><li class=inline-block><a class="bg-theme-light hover:bg-primary dark:bg-darkmode-theme-light dark:hover:bg-darkmode-primary dark:hover:text-dark m-1 block rounded px-3 py-1 hover:text-white" href=/en/tags/%e5%9b%be%e5%83%8f%e5%88%86%e5%89%b2/>图像分割</a></li></ul></div></div></article></div></div></section></main><footer class="bg-theme-light dark:bg-darkmode-theme-light"><div class=container><div class="row items-center py-10"><div class="lg:col-3 mb-8 text-center lg:mb-0 lg:text-left"><a class="navbar-brand inline-block" href=/en/><img fetchpriority=high decoding=async class="img logo-light" width=160 height=32 src=/images/logo_hud3822dc52499c854acb9b180fed4f736_3648_320x0_resize_q80_h2_lanczos_3.webp alt=Hugoplate onerror='this.onerror=null,this.src="/images/logo_hud3822dc52499c854acb9b180fed4f736_3648_320x0_resize_lanczos_3.png"'>
<img fetchpriority=high decoding=async class="img logo-dark" width=160 height=32 src=/images/logo-darkmode_hu95dd250582672ebe0c063cf60eed448f_3090_320x0_resize_q80_h2_lanczos_3.webp alt=Hugoplate onerror='this.onerror=null,this.src="/images/logo-darkmode_hu95dd250582672ebe0c063cf60eed448f_3090_320x0_resize_lanczos_3.png"'></a></div><div class="lg:col-6 mb-8 text-center lg:mb-0"><ul><li class="m-3 inline-block"><a href=/en/about/>个人信息</a></li><li class="m-3 inline-block"><a href=/en/blog/>学习笔记</a></li><li class="m-3 inline-block"><a href=/en/privacy-policy/>相关说明</a></li></ul></div><div class="lg:col-3 mb-8 text-center lg:mb-0 lg:mt-0 lg:text-right"><ul class=social-icons><li><a target=_blank aria-label=github rel="nofollow noopener" href=https://www.github.com/COOOIKX><i class="fab fa-github"></i></a></li><li><a target=_blank aria-label=csdn rel="nofollow noopener" href="https://blog.csdn.net/m0_59701064?spm=1000.2115.3001.5343"><i class="fas fa-home-lg"></i></a></li></ul></div></div></div><div class="border-border dark:border-darkmode-border border-t py-7"><div class="text-light dark:text-darkmode-light container text-center"><p>HeDesigned & Developed by <a href=https://zeon.studio target=_blank>Zeon Studio</a></p></div></div></footer><script crossorigin=anonymous integrity="sha256-YQerunHGeT7hXzxweSqFUXgOHHxFceSjmMy/kmnAHWU=" src=/js/script.min.6107abba71c6793ee15f3c70792a8551780e1c7c4571e4a398ccbf9269c01d65.js></script><script defer async crossorigin=anonymous integrity="sha256-w+aS42D2+B+Jix+joZ7pAua1vbu/pRK/IhoP55b8n3w=" src=/js/script-lazy.min.c3e692e360f6f81f898b1fa3a19ee902e6b5bdbbbfa512bf221a0fe796fc9f7c.js></script><script>"serviceWorker"in navigator&&navigator.serviceWorker.register("/service-worker.js")</script></body></html>